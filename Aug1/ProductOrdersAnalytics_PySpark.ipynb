{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-CXGfgfShV70"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.functions import col, when, sum as _sum, avg, count, rank, month, year\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "spark = SparkSession.builder.appName(\"ProductOrdersAnalytics\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    Row(OrderID=1, CustomerName=\"Ravi\", Product=\"Laptop\", Category=\"Electronics\", Quantity=2, UnitPrice=50000, OrderDate=\"2023-01-15\"),\n",
        "    Row(OrderID=2, CustomerName=\"Anita\", Product=\"T-Shirt\", Category=\"Clothing\", Quantity=4, UnitPrice=700, OrderDate=\"2023-01-20\"),\n",
        "    Row(OrderID=3, CustomerName=\"Kabir\", Product=\"Book A\", Category=\"Books\", Quantity=3, UnitPrice=400, OrderDate=\"2023-02-10\"),\n",
        "    Row(OrderID=4, CustomerName=\"Divya\", Product=\"Sofa\", Category=\"Furniture\", Quantity=1, UnitPrice=12000, OrderDate=\"2023-03-05\"),\n",
        "    Row(OrderID=5, CustomerName=\"Amit\", Product=\"Phone\", Category=\"Electronics\", Quantity=1, UnitPrice=25000, OrderDate=\"2023-01-25\"),\n",
        "    Row(OrderID=6, CustomerName=\"Sneha\", Product=\"Desk\", Category=\"Furniture\", Quantity=2, UnitPrice=8000, OrderDate=\"2023-04-11\"),\n",
        "    Row(OrderID=7, CustomerName=\"Neha\", Product=\"Shoes\", Category=\"Clothing\", Quantity=2, UnitPrice=1500, OrderDate=\"2023-05-02\"),\n",
        "    Row(OrderID=8, CustomerName=\"Rishitha\", Product=\"Book B\", Category=\"Books\", Quantity=5, UnitPrice=350, OrderDate=\"2023-06-18\"),\n",
        "    Row(OrderID=9, CustomerName=\"Savitri\", Product=\"TV\", Category=\"Electronics\", Quantity=3, UnitPrice=40000, OrderDate=\"2023-07-01\"),\n",
        "    Row(OrderID=10, CustomerName=\"Kiran\", Product=\"Bookshelf\", Category=\"Furniture\", Quantity=1, UnitPrice=15000, OrderDate=\"2023-07-20\"),\n",
        "    Row(OrderID=11, CustomerName=\"Farah\", Product=\"Book C\", Category=\"Books\", Quantity=2, UnitPrice=500, OrderDate=\"2023-08-05\"),\n",
        "    Row(OrderID=12, CustomerName=\"Manav\", Product=\"Headphones\", Category=\"Electronics\", Quantity=4, UnitPrice=3000, OrderDate=\"2023-09-09\")\n",
        "]\n",
        "\n",
        "df = spark.createDataFrame(data)\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg2mnII9heG4",
        "outputId": "579f0180-1a9d-4952-e175-111aea50d1f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|Product   |Category   |Quantity|UnitPrice|OrderDate |\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|1      |Ravi        |Laptop    |Electronics|2       |50000    |2023-01-15|\n",
            "|2      |Anita       |T-Shirt   |Clothing   |4       |700      |2023-01-20|\n",
            "|3      |Kabir       |Book A    |Books      |3       |400      |2023-02-10|\n",
            "|4      |Divya       |Sofa      |Furniture  |1       |12000    |2023-03-05|\n",
            "|5      |Amit        |Phone     |Electronics|1       |25000    |2023-01-25|\n",
            "|6      |Sneha       |Desk      |Furniture  |2       |8000     |2023-04-11|\n",
            "|7      |Neha        |Shoes     |Clothing   |2       |1500     |2023-05-02|\n",
            "|8      |Rishitha    |Book B    |Books      |5       |350      |2023-06-18|\n",
            "|9      |Savitri     |TV        |Electronics|3       |40000    |2023-07-01|\n",
            "|10     |Kiran       |Bookshelf |Furniture  |1       |15000    |2023-07-20|\n",
            "|11     |Farah       |Book C    |Books      |2       |500      |2023-08-05|\n",
            "|12     |Manav       |Headphones|Electronics|4       |3000     |2023-09-09|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Local view\n",
        "df.createOrReplaceTempView(\"orders_local\")\n",
        "\n",
        "# Global view\n",
        "df.createOrReplaceGlobalTempView(\"orders_global\")\n"
      ],
      "metadata": {
        "id": "gBKZjhhBhedt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PART-A\n",
        "# 1. List all Electronics orders with Quantity >= 2\n",
        "spark.sql(\"SELECT * FROM orders_local WHERE Category = 'Electronics' AND Quantity >= 2\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQu3ehxhher1",
        "outputId": "ef82f3b4-228d-4374-e612-62e395c4c91b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|      1|        Ravi|    Laptop|Electronics|       2|    50000|2023-01-15|\n",
            "|      9|     Savitri|        TV|Electronics|       3|    40000|2023-07-01|\n",
            "|     12|       Manav|Headphones|Electronics|       4|     3000|2023-09-09|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Calculate TotalAmount (Quantity * UnitPrice) for each order\n",
        "spark.sql(\"SELECT *, (Quantity * UnitPrice) AS TotalAmount FROM orders_local\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmpA-r7-he2v",
        "outputId": "8de32b90-b4b8-4812-9f4c-c784f361b9d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+-----------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+-----------+\n",
            "|      1|        Ravi|    Laptop|Electronics|       2|    50000|2023-01-15|     100000|\n",
            "|      2|       Anita|   T-Shirt|   Clothing|       4|      700|2023-01-20|       2800|\n",
            "|      3|       Kabir|    Book A|      Books|       3|      400|2023-02-10|       1200|\n",
            "|      4|       Divya|      Sofa|  Furniture|       1|    12000|2023-03-05|      12000|\n",
            "|      5|        Amit|     Phone|Electronics|       1|    25000|2023-01-25|      25000|\n",
            "|      6|       Sneha|      Desk|  Furniture|       2|     8000|2023-04-11|      16000|\n",
            "|      7|        Neha|     Shoes|   Clothing|       2|     1500|2023-05-02|       3000|\n",
            "|      8|    Rishitha|    Book B|      Books|       5|      350|2023-06-18|       1750|\n",
            "|      9|     Savitri|        TV|Electronics|       3|    40000|2023-07-01|     120000|\n",
            "|     10|       Kiran| Bookshelf|  Furniture|       1|    15000|2023-07-20|      15000|\n",
            "|     11|       Farah|    Book C|      Books|       2|      500|2023-08-05|       1000|\n",
            "|     12|       Manav|Headphones|Electronics|       4|     3000|2023-09-09|      12000|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Show total number of orders per Category\n",
        "spark.sql(\"SELECT Category, COUNT(*) AS TotalOrders FROM orders_local GROUP BY Category\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iI8ZdqGhfBN",
        "outputId": "ca3ae421-515f-4e87-f12e-3d754f56c384"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+\n",
            "|   Category|TotalOrders|\n",
            "+-----------+-----------+\n",
            "|Electronics|          4|\n",
            "|   Clothing|          2|\n",
            "|      Books|          3|\n",
            "|  Furniture|          3|\n",
            "+-----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. List orders placed in January 2023 only\n",
        "spark.sql(\"SELECT * FROM orders_local WHERE OrderDate LIKE '2023-01%'\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDHZQtXVhfK4",
        "outputId": "57ae8703-e75a-4c15-f056-4927f6163d57"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+\n",
            "|      1|        Ravi| Laptop|Electronics|       2|    50000|2023-01-15|\n",
            "|      2|       Anita|T-Shirt|   Clothing|       4|      700|2023-01-20|\n",
            "|      5|        Amit|  Phone|Electronics|       1|    25000|2023-01-25|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Show average UnitPrice per category\n",
        "spark.sql(\"SELECT Category, AVG(UnitPrice) AS AvgPrice FROM orders_local GROUP BY Category\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq-STFRGhfVZ",
        "outputId": "73662bc6-9b3f-4396-ecc8-5a1ad53868ad"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|   Category|          AvgPrice|\n",
            "+-----------+------------------+\n",
            "|Electronics|           29500.0|\n",
            "|   Clothing|            1100.0|\n",
            "|      Books| 416.6666666666667|\n",
            "|  Furniture|11666.666666666666|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Find the order with the highest total amount\n",
        "spark.sql(\"SELECT *, (Quantity * UnitPrice) AS TotalAmount FROM orders_local ORDER BY TotalAmount DESC LIMIT 1\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh-yN3-ThffI",
        "outputId": "8114ffc7-594d-4434-83d5-6724cfa54078"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "|OrderID|CustomerName|Product|   Category|Quantity|UnitPrice| OrderDate|TotalAmount|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "|      9|     Savitri|     TV|Electronics|       3|    40000|2023-07-01|     120000|\n",
            "+-------+------------+-------+-----------+--------+---------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Drop the local view and try querying again\n",
        "spark.catalog.dropTempView(\"orders_local\")\n",
        "spark.sql(\"SELECT * FROM orders_local\").show()\n",
        "#IT GETS ERROR\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "osHCb3SthgRd",
        "outputId": "25b9ab1c-dd8f-439f-e507-634313a6249e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[TABLE_OR_VIEW_NOT_FOUND] The table or view `orders_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [orders_local], [], false\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3638108039.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 7. Drop the local view and try querying again (you'll get an error)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropTempView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"orders_local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SELECT * FROM orders_local\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will throw an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0m_to_java_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                 )\n\u001b[0;32m-> 1631\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitArgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [TABLE_OR_VIEW_NOT_FOUND] The table or view `orders_local` cannot be found. Verify the spelling and correctness of the schema and catalog.\nIf you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.\nTo tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS.; line 1 pos 14;\n'Project [*]\n+- 'UnresolvedRelation [orders_local], [], false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PART-B\n",
        "#1. Display all Furniture orders with TotalAmount > 10000\n",
        "spark.sql(\"SELECT * FROM global_temp.orders_global WHERE Category = 'Furniture' AND (Quantity * UnitPrice) > 10000\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amMZM9dQhg8_",
        "outputId": "2857672c-c96a-490d-e50b-dce55ea65efd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+---------+---------+--------+---------+----------+\n",
            "|OrderID|CustomerName|  Product| Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+---------+---------+--------+---------+----------+\n",
            "|      4|       Divya|     Sofa|Furniture|       1|    12000|2023-03-05|\n",
            "|      6|       Sneha|     Desk|Furniture|       2|     8000|2023-04-11|\n",
            "|     10|       Kiran|Bookshelf|Furniture|       1|    15000|2023-07-20|\n",
            "+-------+------------+---------+---------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Create a column called DiscountFlag: 'Yes' if Quantity > 3, else 'No'\n",
        "df_discount = df.withColumn(\"DiscountFlag\", when(col(\"Quantity\") > 3, \"Yes\").otherwise(\"No\"))\n",
        "df_discount.createOrReplaceGlobalTempView(\"orders_discounted\")\n",
        "spark.sql(\"SELECT * FROM global_temp.orders_discounted\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_5DzYPWhhhf",
        "outputId": "cf307026-7388-4b40-cfb0-5ddaaadf2b98"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+-----------+--------+---------+----------+------------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|DiscountFlag|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+------------+\n",
            "|      1|        Ravi|    Laptop|Electronics|       2|    50000|2023-01-15|          No|\n",
            "|      2|       Anita|   T-Shirt|   Clothing|       4|      700|2023-01-20|         Yes|\n",
            "|      3|       Kabir|    Book A|      Books|       3|      400|2023-02-10|          No|\n",
            "|      4|       Divya|      Sofa|  Furniture|       1|    12000|2023-03-05|          No|\n",
            "|      5|        Amit|     Phone|Electronics|       1|    25000|2023-01-25|          No|\n",
            "|      6|       Sneha|      Desk|  Furniture|       2|     8000|2023-04-11|          No|\n",
            "|      7|        Neha|     Shoes|   Clothing|       2|     1500|2023-05-02|          No|\n",
            "|      8|    Rishitha|    Book B|      Books|       5|      350|2023-06-18|         Yes|\n",
            "|      9|     Savitri|        TV|Electronics|       3|    40000|2023-07-01|          No|\n",
            "|     10|       Kiran| Bookshelf|  Furniture|       1|    15000|2023-07-20|          No|\n",
            "|     11|       Farah|    Book C|      Books|       2|      500|2023-08-05|          No|\n",
            "|     12|       Manav|Headphones|Electronics|       4|     3000|2023-09-09|         Yes|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. List customers who ordered more than one product type\n",
        "spark.sql(\"\"\"SELECT CustomerName\n",
        "  FROM global_temp.orders_global\n",
        "  GROUP BY CustomerName\n",
        "  HAVING COUNT(DISTINCT Category) > 1\n",
        "\"\"\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GW96GNmXhihN",
        "outputId": "82888488-145e-476a-c88f-f961cafacf91"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|CustomerName|\n",
            "+------------+\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Count number of orders per month\n",
        "df_month = df.withColumn(\"Month\", month(col(\"OrderDate\")))\n",
        "df_month.createOrReplaceGlobalTempView(\"orders_by_month\")\n",
        "spark.sql(\"SELECT Month, COUNT(*) AS OrdersCount FROM global_temp.orders_by_month GROUP BY Month ORDER BY Month\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3tQGq7ahjCj",
        "outputId": "c6c487bc-eb11-432e-f7f2-ab742f24cafe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+\n",
            "|Month|OrdersCount|\n",
            "+-----+-----------+\n",
            "|    1|          3|\n",
            "|    2|          1|\n",
            "|    3|          1|\n",
            "|    4|          1|\n",
            "|    5|          1|\n",
            "|    6|          1|\n",
            "|    7|          2|\n",
            "|    8|          1|\n",
            "|    9|          1|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Rank all products by total quantity sold across all orders\n",
        "windowSpec = Window.orderBy(col(\"TotalQtySold\").desc())\n",
        "product_totals = df.groupBy(\"Product\").agg(_sum(\"Quantity\").alias(\"TotalQtySold\"))\n",
        "ranked = product_totals.withColumn(\"Rank\", rank().over(windowSpec))\n",
        "ranked.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxW7SqG8hjl3",
        "outputId": "810d3286-6858-44af-999d-528fe2884cb6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+----+\n",
            "|   Product|TotalQtySold|Rank|\n",
            "+----------+------------+----+\n",
            "|    Book B|           5|   1|\n",
            "|   T-Shirt|           4|   2|\n",
            "|Headphones|           4|   2|\n",
            "|    Book A|           3|   4|\n",
            "|        TV|           3|   4|\n",
            "|      Desk|           2|   6|\n",
            "|    Laptop|           2|   6|\n",
            "|     Shoes|           2|   6|\n",
            "|    Book C|           2|   6|\n",
            "|     Phone|           1|  10|\n",
            "|      Sofa|           1|  10|\n",
            "| Bookshelf|           1|  10|\n",
            "+----------+------------+----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Run a query using a new Spark session and the global view\n",
        "new_spark = SparkSession.builder.appName(\"NewSession\").getOrCreate()\n",
        "new_spark.sql(\"SELECT * FROM global_temp.orders_global\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyXhcYO1ikAy",
        "outputId": "0b4238d6-53af-4634-bc10-4d2defaf10bb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|      1|        Ravi|    Laptop|Electronics|       2|    50000|2023-01-15|\n",
            "|      2|       Anita|   T-Shirt|   Clothing|       4|      700|2023-01-20|\n",
            "|      3|       Kabir|    Book A|      Books|       3|      400|2023-02-10|\n",
            "|      4|       Divya|      Sofa|  Furniture|       1|    12000|2023-03-05|\n",
            "|      5|        Amit|     Phone|Electronics|       1|    25000|2023-01-25|\n",
            "|      6|       Sneha|      Desk|  Furniture|       2|     8000|2023-04-11|\n",
            "|      7|        Neha|     Shoes|   Clothing|       2|     1500|2023-05-02|\n",
            "|      8|    Rishitha|    Book B|      Books|       5|      350|2023-06-18|\n",
            "|      9|     Savitri|        TV|Electronics|       3|    40000|2023-07-01|\n",
            "|     10|       Kiran| Bookshelf|  Furniture|       1|    15000|2023-07-20|\n",
            "|     11|       Farah|    Book C|      Books|       2|      500|2023-08-05|\n",
            "|     12|       Manav|Headphones|Electronics|       4|     3000|2023-09-09|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BONUS\n",
        "# 1. Save a filtered subset (only \"Books\" category) as a new global temp view\n",
        "spark.sql(\"\"\"CREATE OR REPLACE GLOBAL TEMP VIEW books_only AS\n",
        "  SELECT * FROM global_temp.orders_global WHERE Category = 'Books'\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkLuE-fpik_b",
        "outputId": "5e0eb886-634a-4f2b-d837-2b2a14e1cd25"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the \"Books\" only dataset\n",
        "spark.sql(\"SELECT * FROM global_temp.books_only\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mk4BoL7il6O",
        "outputId": "eef0c92f-ea8e-4ad9-90d1-c16f4d053aea"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+-------+--------+--------+---------+----------+\n",
            "|OrderID|CustomerName|Product|Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+-------+--------+--------+---------+----------+\n",
            "|      3|       Kabir| Book A|   Books|       3|      400|2023-02-10|\n",
            "|      8|    Rishitha| Book B|   Books|       5|      350|2023-06-18|\n",
            "|     11|       Farah| Book C|   Books|       2|      500|2023-08-05|\n",
            "+-------+------------+-------+--------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import row_number\n",
        "windowSpec = Window.partitionBy(\"Category\").orderBy(col(\"TotalQty\").desc())\n",
        "\n",
        "most_purchased = df.groupBy(\"Category\", \"Product\").agg(_sum(\"Quantity\").alias(\"TotalQty\"))\n",
        "most_purchased = most_purchased.withColumn(\"rn\", row_number().over(windowSpec)).filter(\"rn = 1\")\n",
        "most_purchased.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPgCUTGAjH8O",
        "outputId": "93303cf1-ae4f-461b-a504-e7370414bac1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+--------+---+\n",
            "|   Category|   Product|TotalQty| rn|\n",
            "+-----------+----------+--------+---+\n",
            "|      Books|    Book B|       5|  1|\n",
            "|   Clothing|   T-Shirt|       4|  1|\n",
            "|Electronics|Headphones|       4|  1|\n",
            "|  Furniture|      Desk|       2|  1|\n",
            "+-----------+----------+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create a view that excludes all \"Clothing\" orders and call it \"filtered_orders\"\n",
        "spark.sql(\"\"\"\n",
        "  CREATE OR REPLACE GLOBAL TEMP VIEW filtered_orders AS\n",
        "  SELECT * FROM global_temp.orders_global WHERE Category != 'Clothing'\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W46IH-njLwj",
        "outputId": "2d315fef-7bdc-4e40-80ad-b10e9da51070"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the filtered orders\n",
        "spark.sql(\"SELECT * FROM global_temp.filtered_orders\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzAQeQgcjPj2",
        "outputId": "f1413b07-aed5-40f7-b590-f4d5911a84d0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|OrderID|CustomerName|   Product|   Category|Quantity|UnitPrice| OrderDate|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "|      1|        Ravi|    Laptop|Electronics|       2|    50000|2023-01-15|\n",
            "|      3|       Kabir|    Book A|      Books|       3|      400|2023-02-10|\n",
            "|      4|       Divya|      Sofa|  Furniture|       1|    12000|2023-03-05|\n",
            "|      5|        Amit|     Phone|Electronics|       1|    25000|2023-01-25|\n",
            "|      6|       Sneha|      Desk|  Furniture|       2|     8000|2023-04-11|\n",
            "|      8|    Rishitha|    Book B|      Books|       5|      350|2023-06-18|\n",
            "|      9|     Savitri|        TV|Electronics|       3|    40000|2023-07-01|\n",
            "|     10|       Kiran| Bookshelf|  Furniture|       1|    15000|2023-07-20|\n",
            "|     11|       Farah|    Book C|      Books|       2|      500|2023-08-05|\n",
            "|     12|       Manav|Headphones|Electronics|       4|     3000|2023-09-09|\n",
            "+-------+------------+----------+-----------+--------+---------+----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}